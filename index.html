<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<!-- saved from url=(0039)https://view-parsing-network.github.io/ -->
<html xmlns="http://www.w3.org/1999/xhtml" class="gr__physplus_csail_mit_edu gr__view-parsing-network_github_io"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

    <script src="./View_Parsing_Network_files/head.js"></script>        <meta name="viewport" content="width=device-width, initial-scale=1">    <link rel="shortcut icon" href="https://view-parsing-network.github.io/undefinedimages/favicon.ico">        
    <meta name="viewport" content="width=device-width, initial-scale=1">    <link rel="shortcut icon" href="http://physplus.csail.mit.edu/images/favicon.ico">
    <meta name="description" content="View_Parsing_Network">
    <meta name="keywords" content="MIT,Vision,Scene Understanding,Learning,Computer Science">

    <title>View Parsing Network</title>
    <link rel="stylesheet" href="./View_Parsing_Network_files/font.css">
    <link rel="stylesheet" href="./View_Parsing_Network_files/main.css">

  </head>

  <body data-gr-c-s-loaded="true">

    <div class="outercontainer">
      <div class="container">

        <div class="content project_title">
          <h1>Cross-view Semantic Segmentation for Sensing Surroundings</h1>

          <p id="authors">
          	<a href="http://people.csail.mit.edu/bpan/">Bowen Pan<sup>1</sup></a>,
            <a href="https://jiankaisun.github.io/">Jiankai Sun<sup>2</sup></a>,
  			<a href="https://www.alexandonian.com/">Alex Andonian<sup>1</sup></a>,
  			<a href="http://bzhou.ie.cuhk.edu.hk/">Bolei Zhou<sup>2</sup></a><br>
  			<sup>1</sup>Massachusetts Institute of Technology,  <sup>2</sup>The Chinese University of Hong Kong
          </p>
          <p>
            [<a href="./View_Parsing_Network_files/VPN_v2_for_CVPR2020.pdf">PDF</a>] [<a href="https://arxiv.org/abs/1906.03560">arXiv</a>] [<a href="https://github.com/pbw-Berwin/View-Parsing-Network">Code</a>] [<a href="./View_Parsing_Network_files/Supplementary_Material_VPN_v2 .pdf">Supplemental Materials</a>]
          </p>
        </div>
              
        <div class="content project_headline">
          <div class="img" style="text-align:center">
            <img class="img_responsive" src="./View_Parsing_Network_files/demo_fig_traffic.png" alt="Teaser" style="margin:auto;max-width:50%">
          </div>
          <div class="text">
            <p>We introduce a novel spatial understanding task calls <strong>Cross-view Semantic Segmentation</strong>. In this task, top-down-view semantics are predicted from the first-view real-world observations. Input observations from multiple angles are fused together.</p>
          </div>
        </div>
        
        <h2 align='center'>Overview</h2>
        <div align="center" style="text-align: left;">
            <p>
                In this framework, the View Parsing Network (VPN) is proposed to parse the first-view observations into a top-down-view semantic map indicating the spatial location of all the objects at pixel-level. The view transformer module contained in VPN is designed to aggregate the surrounding information collected from first-view observations in multiple angles and modalities. To mitigate the issue of lacking real-world annotations, we train the VPN in simulation environment and utilize the off-the-shelf domain adaptation technique to transfer it to real-world data. 
                We evaluate our VPN on both synthetic and real-world data. The experimental results show that our model can effectively make use of the information from different views and multi-modalities. Thus the proposed VPN is able to accurately predict the top-down-view semantic mask of the visible objects as well as barely seen objects, in both synthetic and real-world environments.
            </p>
        </div>

        <h3 align='center'>Pipelines</h3>
        <div align="center" style="text-align: left;">
            <div class="img" style="text-align:left">
                <img class="img_responsive" src="./View_Parsing_Network_files/framework_full.png" alt="Teaser" style="margin:auto;max-width:80%">
                <p>
                    Framework of the View Parsing Network for cross-view semantic segmentation. The simulation part illustrates the architecture and training scheme of our VPN. And the real-world part demonstrates our domain adaptation process for transferring our VPN to the real world.
                </p>
            </div>
        </div>

        <div class="content">
                    <div class="text">
                        <!-- <h3>Preprint</h3> -->
                        <table>
                            <tbody>
                                <tr>
                                    <td>
                                        <ul>
                                  	<h3>Paper</h3>
              
  							<div><a href="./View_Parsing_Network_files/VPN_v2_for_CVPR2020.pdf" target="_blank"><img src="./View_Parsing_Network_files/first-page.png" alt="" style="width: 50%; margin: -0.0000014107% 0 -0.0000014107% 0%"></a></div>
              	<!-- <div class="jz"><a href="https://github.com/pbw-Berwin/View-Parsing-Network"><br>Code for training and testing <br> (Github Repo)</a></div> -->
                </ul>
                                   </td>
                                    <td style="vertical-align:middle">
                                        <h3>GIF Highlight (real-world results)</h3>
                                        <div><img src="./View_Parsing_Network_files/ezgif.com-crop.gif" alt="" style="width: 100%; padding-bottom: 11%; padding-top: 11%; margin: -0.0000014107% 0 -0.0000014107% 0%"></div>
                                    </td>
                                </tr>
                            </tbody>
                        </table>
                    </div>
        </div>

        <div align="center" style="padding-bottom: 10%;">
          <h3>Demo Video</h3>
            <iframe width="560" height="315" src="https://www.youtube.com/embed/zyeHpdsLj5s" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
        </div>

    </div>
    </div>

  



</body></html>